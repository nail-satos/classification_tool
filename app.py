""" streamlit_demo
streamlitã§Irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†æçµæœã‚’ Web ã‚¢ãƒ—ãƒªåŒ–ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã€Streamlit å…¥é–€ 1ã€‘Streamlit ã§æ©Ÿæ¢°å­¦ç¿’ã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªä½œæˆ â€“ DogsCox's tech. blog
https://dogscox-trivial-tech-blog.com/posts/streamlit_demo_iris_decisiontree/
"""

from itertools import chain
import numpy as np
import pandas as pd 
import streamlit as st
import matplotlib.pyplot as plt 
import japanize_matplotlib
import seaborn as sns 
# import graphviz
# import plotly.graph_objects as go
# irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆã™ã‚‹
# from sklearn.datasets import load_iris

# æ±ºå®šæœ¨
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier

# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ
from sklearn.ensemble import RandomForestClassifier

# ç²¾åº¦è©•ä¾¡ç”¨
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€
from sklearn.model_selection import train_test_split

# ãƒ‡ãƒ¼ã‚¿ã‚’æ°´å¢—ã—ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€
from imblearn.over_sampling import SMOTE

# ãƒ­ã‚´ã®è¡¨ç¤ºç”¨
from PIL import Image

# ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼
import copy

sns.set()
japanize_matplotlib.japanize()  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š

# matplotlib / seaborn ã®æ—¥æœ¬èªã®æ–‡å­—åŒ–ã‘ã‚’ç›´ã™ã€æ±ç”¨çš„ã‹ã¤ä¸€ç•ªç°¡å˜ãªè¨­å®šæ–¹æ³• | BOUL
# https://boul.tech/mplsns-ja/


def st_display_table(df: pd.DataFrame):

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
    st.subheader('ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª')
    # st.caption('æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™')
    st.table(df)

    # Streamlitã§dataframeã‚’è¡¨ç¤ºã•ã›ã‚‹ | ITãƒ–ãƒ­ã‚°
    # https://kajiblo.com/streamlit-dataframe/


def st_display_histogram(df: pd.DataFrame, x_col, hue_col):

    fig, ax = plt.subplots()
    # plt.title("ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ", fontsize=20)     # (3) ã‚¿ã‚¤ãƒˆãƒ«
    # plt.xlabel("Age", fontsize=20)          # (4) xè»¸ãƒ©ãƒ™ãƒ«
    # plt.ylabel("Frequency", fontsize=20)      # (5) yè»¸ãƒ©ãƒ™ãƒ«
    plt.grid(True)                            # (6) ç›®ç››ç·šã®è¡¨

    if hue_col == 'null':
        unique_cnt = len(df[x_col].value_counts())
        if unique_cnt > 10:
            plt.xlabel(x_col, fontsize=12)          # xè»¸ãƒ©ãƒ™ãƒ«
            plt.hist(df[x_col])   # å˜ãªã‚‹ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        else:
            sns.countplot(data=df, x=x_col, ax=ax)
    else:
        sns.countplot(data=df, x=x_col, hue=hue_col, ax=ax)

    st.pyplot(fig)

    # seabornã§ã‚°ãƒ©ãƒ•ã‚’è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ã‚’æç”»ã™ã‚‹ - Qiita
    # https://qiita.com/tomokitamaki/items/b954e26be739bee5621e



def ml_dtree(
    X: pd.DataFrame,
    y: pd.Series,
    depth: int) -> list:
    """ æ±ºå®šæœ¨ã§å­¦ç¿’ã€äºˆæ¸¬ã‚’è¡Œã†é–¢æ•°
    Irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã§å­¦ç¿’ã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬å€¤ã‚’è¿”ã™é–¢æ•°
    Args:
        X(pd.DataFrame): èª¬æ˜å¤‰æ•°éƒ¡
        y(pd.Series): ç›®çš„å¤‰æ•°
    
    Returns:
        List: [ãƒ¢ãƒ‡ãƒ«, å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’äºˆæ¸¬ã—ãŸäºˆæ¸¬å€¤, accuracy]ã®ãƒªã‚¹ãƒˆ
    """
    # å­¦ç¿’
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X, y)

    # äºˆæ¸¬
    pred = clf.predict(X)

    # accuracyã§ç²¾åº¦è©•ä¾¡
    score = accuracy_score(y, pred)

    return [clf, pred, score]


def st_display_dtree(clf, features):
    """æ±ºå®šæœ¨å¯è¦–åŒ–é–¢æ•°
    streamlitã§DtreeVizã«ã‚ˆã‚‹æ±ºå®šæœ¨ã‚’å¯è¦–åŒ–ã™ã‚‹é–¢æ•°
    Args:
        clf(sklearn.DecisionTreeClassifier): å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    Return:
    """
    # # graphvizã§æ±ºå®šæœ¨ã‚’å¯è¦–åŒ–
    # dot = tree.export_graphviz(clf, out_file=None)
    # # stã§è¡¨ç¤ºã™ã‚‹
    # st.graphviz_chart(dot)

    dot = tree.export_graphviz(clf, 
                               out_file=None, # ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»‹ã•ãšã«Graphvizã«dotè¨€èªãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ã®ã§None
                               filled=True, # Trueã«ã™ã‚‹ã¨ã€åˆ†å²ã®éš›ã«ã©ã¡ã‚‰ã®ãƒãƒ¼ãƒ‰ã«å¤šãåˆ†é¡ã•ã‚ŒãŸã®ã‹è‰²ã§ç¤ºã—ã¦ãã‚Œã‚‹
                               rounded=True, # Trueã«ã™ã‚‹ã¨ã€ãƒãƒ¼ãƒ‰ã®è§’ã‚’ä¸¸ãæç”»ã™ã‚‹ã€‚
                            #    feature_names=['ã‚', 'ã„', 'ã†', 'ãˆ'], # ã“ã‚Œã‚’æŒ‡å®šã—ãªã„ã¨ãƒãƒ£ãƒ¼ãƒˆä¸Šã§ç‰¹å¾´é‡ã®åå‰ãŒè¡¨ç¤ºã•ã‚Œãªã„
                               feature_names=features, # ã“ã‚Œã‚’æŒ‡å®šã—ãªã„ã¨ãƒãƒ£ãƒ¼ãƒˆä¸Šã§ç‰¹å¾´é‡ã®åå‰ãŒè¡¨ç¤ºã•ã‚Œãªã„
                            #    class_names=['setosa' 'versicolor' 'virginica'], # ã“ã‚Œã‚’æŒ‡å®šã—ãªã„ã¨ãƒãƒ£ãƒ¼ãƒˆä¸Šã§åˆ†é¡åãŒè¡¨ç¤ºã•ã‚Œãªã„
                               special_characters=True # ç‰¹æ®Šæ–‡å­—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
                               )

    # stã§è¡¨ç¤ºã™ã‚‹
    st.graphviz_chart(dot)


def st_display_rtree(clf, features):

    # é‡è¦åº¦ã®æŠ½å‡º
    feature_importances = pd.Series(clf.feature_importances_, index=features).sort_values(ascending=True)
    feature_importances = feature_importances.to_frame(name='é‡è¦åº¦').sort_values(by='é‡è¦åº¦', ascending=False)

    # TOP20å¯è¦–åŒ–
    feature_importances[0:20].sort_values(by='é‡è¦åº¦').plot.barh()
    plt.legend(loc='lower right')
    # plt.show()
    st.pyplot(plt)


def st_display_confusion_matrix(y_true, y_pred, labels):
    """æ··åŒè¡Œåˆ—ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤ºã™ã‚‹é–¢æ•°"""
    cm = confusion_matrix(y_true, y_pred, labels=labels)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    
    # ã‚°ãƒ©ãƒ•ã®æç”»
    fig, ax = plt.subplots()
    disp.plot(ax=ax, cmap='Blues')
    plt.xticks(rotation=45)
    st.pyplot(fig)


def ml_drtree_pred(
    X: pd.DataFrame,
    y: pd.Series,
    algorithm,
    t_size: float,
    use_smote: bool,
    params: dict) -> list:

    # train_test_splité–¢æ•°ã‚’åˆ©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹
    train_x, valid_x, train_y, valid_y = train_test_split(X, y, train_size=t_size, random_state=0, stratify=y)

    # use_smoteãŒTrueã®å ´åˆã®ã¿ã€SMOTEå‡¦ç†ã‚’å®Ÿè¡Œ
    if use_smote:
        st.info("SMOTEã‚’æœ‰åŠ¹ã«ã—ã¦ã€å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è£œæ­£ã—ã¾ã—ãŸã€‚")
        try:
            oversample = SMOTE(random_state=0)
            train_x, train_y = oversample.fit_resample(train_x, train_y)
        except ValueError:
            # ã‚¯ãƒ©ã‚¹æ•°ãŒ1ã¤ã®å ´åˆã‚„ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªãSMOTEãŒé©ç”¨ã§ããªã„å ´åˆã«ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹
            st.warning("SMOTEã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé©ç”¨ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¯ãƒ©ã‚¹ã®æ¯”ç‡ãŒä¸å‡è¡¡ãªå ´åˆã€ç²¾åº¦ãŒåã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            pass
    
    if algorithm == 'dtree':
        # åˆ†é¡å™¨ã®è¨­å®š
        clf = DecisionTreeClassifier(random_state=0, **params)

    elif algorithm == 'rtree':
        # åˆ†é¡å™¨ã®è¨­å®š
        clf = RandomForestClassifier(random_state=0, **params)

    # å­¦ç¿’
    clf.fit(train_x, train_y)

    # æˆ»ã‚Šå€¤ã®åˆæœŸåŒ–
    train_scores = []
    valid_scores = []

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ ï¼† ç²¾åº¦è©•ä¾¡
    train_pred = clf.predict(train_x)
    
    # ã‚¹ã‚³ã‚¢è¨ˆç®— (å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã«å¯¾å¿œ)
    train_scores.append(round(accuracy_score(train_y, train_pred), 3))
    train_scores.append(round(recall_score(train_y, train_pred, average='macro', zero_division=0), 3))
    train_scores.append(round(precision_score(train_y, train_pred, average='macro', zero_division=0), 3))
    train_scores.append(round(f1_score(train_y, train_pred, average='macro', zero_division=0), 3))
    
    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ ï¼† ç²¾åº¦è©•ä¾¡
    valid_pred = clf.predict(valid_x)
    valid_scores.append(round(accuracy_score(valid_y, valid_pred), 3))
    valid_scores.append(round(recall_score(valid_y, valid_pred, average='macro', zero_division=0), 3))
    valid_scores.append(round(precision_score(valid_y, valid_pred, average='macro', zero_division=0), 3))
    valid_scores.append(round(f1_score(valid_y, valid_pred, average='macro', zero_division=0), 3))

    return [clf, train_y, train_pred, train_scores, valid_y, valid_pred, valid_scores]


@st.cache_data # Streamlitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã§ã€åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å†èª­ã¿è¾¼ã¿ã—ãªã„
def load_csv_with_encoding_detection(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ§˜ã€…ãªæ–‡å­—ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦è¿”ã™ã€‚
    """
    if uploaded_file is None:
        return None

    # è©¦è¡Œã™ã‚‹æ–‡å­—ã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']
    
    for enc in encodings:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä½ç½®ã‚’å…ˆé ­ã«æˆ»ã™
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding=enc)
            # èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ãŸã‚‰ã€ã©ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ãŒä½¿ã‚ã‚ŒãŸã‹è¡¨ç¤ºã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™
            st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ–‡å­—ã‚³ãƒ¼ãƒ‰ '{enc}' ã§æ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
            return df
        except Exception:
            # å¤±æ•—ã—ãŸå ´åˆã¯æ¬¡ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã™
            continue
            
    # å…¨ã¦ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¯¾å¿œã—ã¦ã„ã‚‹æ–‡å­—ã‚³ãƒ¼ãƒ‰ (UTF-8, SHIFT-JIS) ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    return None


def main():
    """ ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    """
    # stã®ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.title("Simple AutoML Demo\nï¼ˆMaschine Learning)")

    # ã‚µã‚¤ãƒ‰ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¨­å®š
    activities = ["ãƒ‡ãƒ¼ã‚¿ç¢ºèª", "è¦ç´„çµ±è¨ˆé‡", "ã‚°ãƒ©ãƒ•è¡¨ç¤º", "å­¦ç¿’ã¨æ¤œè¨¼", "About"]
    choice = st.sidebar.selectbox("Select Activity", activities)

    # Aboutç”»é¢ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«ä¾å­˜ã—ãªã„ã®ã§å…ˆã«å‡¦ç†
    if choice == 'About':
        image = Image.open('logo_nail.png')
        st.image(image)
        st.markdown("Built by [Nail Team]")
        st.text("Version 0.4") # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—
        st.markdown("For More Information check out   (https://nai-lab.com/)")
        return # Aboutç”»é¢ã‚’è¡¨ç¤ºã—ãŸã‚‰å‡¦ç†ã‚’çµ‚äº†

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.sidebar.file_uploader("è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type='csv') 

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã¾ã§ã“ã“ã§å‡¦ç†ã‚’ä¸­æ–­
    if uploaded_file is None:
        st.subheader('ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„')
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦èª­ã¿è¾¼ã¿
    df = load_csv_with_encoding_detection(uploaded_file)
    
    # èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’ä¸­æ–­
    if df is None:
        return

    # --- å„æ©Ÿèƒ½ã®è¡¨ç¤º ---
    if choice == 'ãƒ‡ãƒ¼ã‚¿ç¢ºèª':
        st.subheader('ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª')
        cnt = st.sidebar.slider('è¡¨ç¤ºã™ã‚‹ä»¶æ•°', 1, len(df), 10)
        st.table(df.head(int(cnt)))

    elif choice == 'è¦ç´„çµ±è¨ˆé‡':
        st.subheader('è¦ç´„çµ±è¨ˆé‡')
        st.table(df.describe())

    elif choice == 'ã‚°ãƒ©ãƒ•è¡¨ç¤º':
        st.subheader('ã‚°ãƒ©ãƒ•è¡¨ç¤º')
        # hue_col = df.columns[0]     # 'é€€è·'
        x_col = st.sidebar.selectbox("ã‚°ãƒ©ãƒ•ã®Xè»¸", df.columns)
        st_display_histogram(df, x_col, 'null')

    elif choice == 'å­¦ç¿’ã¨æ¤œè¨¼':
        st.subheader('å­¦ç¿’ã¨æ¤œè¨¼')

        # --- 1. åˆ†æè¨­å®š ---
        st.sidebar.markdown("### 1. åˆ†æè¨­å®š")
        # ç›®çš„å¤‰æ•°ã®é¸æŠ
        target_col = st.sidebar.selectbox(
            'ç›®çš„å¤‰æ•°ï¼ˆäºˆæ¸¬ã—ãŸã„é …ç›®ï¼‰',
            df.columns,
            help="äºˆæ¸¬ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã‚’é¸ã³ã¾ã™ã€‚åˆ†é¡å•é¡Œã«é©ã—ãŸã€ã‚«ãƒ†ã‚´ãƒªã‚„å°‘æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’æŒã¤åˆ—ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚"
        )
        # èª¬æ˜å¤‰æ•°ã®é¸æŠ
        feature_cols = st.sidebar.multiselect(
            'èª¬æ˜å¤‰æ•°ï¼ˆäºˆæ¸¬ã«ä½¿ã†é …ç›®ï¼‰',
            [col for col in df.columns if col != target_col],
            default=[col for col in df.columns if col != target_col],
            help="äºˆæ¸¬ã®ãŸã‚ã«ä½¿ç”¨ã™ã‚‹åˆ—ã‚’è¤‡æ•°é¸æŠã—ã¾ã™ã€‚ç›®çš„å¤‰æ•°ã¨ã—ã¦é¸ã‚“ã åˆ—ã¯ã€ã“ã“ã§ã¯é¸æŠã§ãã¾ã›ã‚“ã€‚"
        )

        # --- 2. ãƒ¢ãƒ‡ãƒ«è¨­å®š ---
        st.sidebar.markdown("### 2. ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        algorithm = st.sidebar.selectbox("å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", ["æ±ºå®šæœ¨", "ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ"])

        # --- ä»»æ„è¨­å®š ---
        with st.sidebar.expander("ï¼ˆä»»æ„ï¼‰ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†è¨­å®š"):
            train_size_percentage = st.slider(
                'è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ (%)', 
                min_value=10, max_value=90, value=70, step=5,
                help="è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²æ¯”ç‡ã‚’æŒ‡å®šã—ã¾ã™ã€‚"
            )
            use_smote = st.checkbox(
                "ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’è£œæ­£ã™ã‚‹ (SMOTE)", 
                value=False,
                help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’äººå·¥çš„ã«å¢—ã‚„ã—ã€ã‚¯ãƒ©ã‚¹é–“ã®ä¸å‡è¡¡ã‚’æ˜¯æ­£ã—ã¾ã™ã€‚"
            )

        with st.sidebar.expander("ï¼ˆä»»æ„ï¼‰ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š"):
            params = {}
            if algorithm == 'æ±ºå®šæœ¨':
                params = {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1}
                params['criterion'] = st.selectbox('åˆ†å‰²åŸºæº–', ['gini', 'entropy'], key='dt_criterion')
                params['max_depth'] = st.slider('æœ¨ã®æ·±ã•', 1, 20, params['max_depth'], key='dt_max_depth')
                params['min_samples_leaf'] = st.slider('è‘‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°', 1, 50, params['min_samples_leaf'], key='dt_min_samples_leaf')
            elif algorithm == 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ':
                params = {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1}
                params['n_estimators'] = st.slider('æœ¨ã®æ•°', 10, 300, params['n_estimators'], 10, key='rf_n_estimators')
                params['criterion'] = st.selectbox('åˆ†å‰²åŸºæº–', ['gini', 'entropy'], key='rf_criterion')
                params['max_depth'] = st.slider('å„æœ¨ã®æœ€å¤§æ·±åº¦', 1, 20, params['max_depth'], key='rf_max_depth')
                params['min_samples_leaf'] = st.slider('è‘‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°', 1, 50, params['min_samples_leaf'], key='rf_min_samples_leaf')

        # --- 3. å­¦ç¿’å®Ÿè¡Œ ---
        st.sidebar.markdown("### 3. å­¦ç¿’å®Ÿè¡Œ")
        if st.sidebar.button('å­¦ç¿’ã‚’å®Ÿè¡Œ', key='train_button'):
            # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ ---
            if not feature_cols:
                st.warning("èª¬æ˜å¤‰æ•°ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
                return
            if df[target_col].nunique() < 2:
                st.error(f"ç›®çš„å¤‰æ•° '{target_col}' ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒ1ã¤ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚")
                return
            target_dtype = df[target_col].dtype
            target_nunique = df[target_col].nunique()
            if np.issubdtype(target_dtype, np.number) and target_nunique > 20:
                st.error(f"ç›®çš„å¤‰æ•° '{target_col}' ã¯é€£ç¶šå€¤ã®ã‚ˆã†ã§ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯åˆ†é¡å°‚ç”¨ã§ã™ã€‚")
                return
            if target_nunique > 10:
                 st.warning(f"ç›®çš„å¤‰æ•° '{target_col}' ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒ10å€‹ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")
            
            # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›
            original_cols = df[feature_cols].columns
            train_X = pd.get_dummies(df[feature_cols], drop_first=True)
            encoded_cols = train_X.columns
            newly_added_cols = set(encoded_cols) - set(original_cols)
            if newly_added_cols:
                st.info(f"ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã—ã¾ã—ãŸ:\n {', '.join(sorted(list(newly_added_cols)))}")
            train_Y = df[target_col]
            
            try:
                # --- å­¦ç¿’ã¨äºˆæ¸¬ ---
                train_size_float = train_size_percentage / 100.0
                algorithm_key = 'dtree' if algorithm == 'æ±ºå®šæœ¨' else 'rtree'
                
                (
                    clf, train_y_resampled, train_pred, train_scores,
                    valid_y, valid_pred, valid_scores
                ) = ml_drtree_pred(
                    train_X, train_Y, algorithm_key, train_size_float, use_smote, params
                )
                
                # --- çµæœã®è¡¨ç¤º ---
                st.subheader("ğŸ“Š äºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡")
                
                tab1, tab2 = st.tabs(["è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡", "æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡"])

                with tab1:
                    st.write("#### è©•ä¾¡æŒ‡æ¨™")
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric('æ­£è§£ç‡', train_scores[0])
                    col2.metric('å†ç¾ç‡', train_scores[1])
                    col3.metric('é©åˆç‡', train_scores[2])
                    col4.metric('F1ã‚¹ã‚³ã‚¢', train_scores[3])
                    
                    st.write("#### æ··åŒè¡Œåˆ— (Confusion Matrix)")
                    if use_smote:
                        st.caption("SMOTEã«ã‚ˆã£ã¦å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ°´å¢—ã—ã•ã‚ŒãŸå¾Œã®ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚")
                    labels = sorted(train_Y.unique())
                    st_display_confusion_matrix(train_y_resampled, train_pred, labels)

                with tab2:
                    st.write(f"#### è©•ä¾¡æŒ‡æ¨™ (è¨“ç·´{train_size_percentage}% / æ¤œè¨¼{100-train_size_percentage}%)")
                    col5, col6, col7, col8 = st.columns(4)
                    col5.metric('æ­£è§£ç‡', valid_scores[0])
                    col6.metric('å†ç¾ç‡', valid_scores[1])
                    col7.metric('é©åˆç‡', valid_scores[2])
                    col8.metric('F1ã‚¹ã‚³ã‚¢', valid_scores[3])

                    st.write("#### æ··åŒè¡Œåˆ— (Confusion Matrix)")
                    st_display_confusion_matrix(valid_y, valid_pred, labels)

                st.subheader("ğŸ§  ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–")
                if algorithm == 'æ±ºå®šæœ¨':
                    st.write("#### æ±ºå®šæœ¨ã®å¯è¦–åŒ–")
                    st_display_dtree(clf, train_X.columns.tolist())
                elif algorithm == 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ':
                    st.write("#### ç‰¹å¾´é‡ã®é‡è¦åº¦")
                    st_display_rtree(clf, train_X.columns.tolist())

            except Exception as e:
                st.error("å­¦ç¿’ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                st.info("ç›®çš„å¤‰æ•°ã®é¸æŠãŒé©åˆ‡ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°ã®è¡¨ç¤º"):
                    st.exception(e)
        

if __name__ == "__main__":
    main()

